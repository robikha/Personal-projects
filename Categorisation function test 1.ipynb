{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section connects to the sql database which holds the accounting test data\n",
    "\n",
    "import pyodbc \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = 'obr-mvp-eun-s-sql.database.windows.net' \n",
    "database = 'OBRPlatform' \n",
    "#username = os.environ.get('OpenRep_DB_USERNAME') \n",
    "#password = os.environ.get('OpenRep_DB_PASSWORD')  \n",
    "username = \"C0a5827cvVC2c15\"\n",
    "password = \"291C02k891e1a_d\"\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+ str(username)+';PWD='+ str(password))\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorisation (party1) :\n",
    "\n",
    "   c = cursor.execute(\"\"\"\n",
    "\n",
    "   Declare @listOfIds Char(100) =(?)\n",
    "\n",
    "   SELECT  PartyId, \n",
    "        Id, \n",
    "        ContainerType, \n",
    "        QualifiedCategory,  \n",
    "        QualifiedName, \n",
    "        Description,\n",
    "        CASE  \n",
    "        WHEN ContainerType = 'Income' \n",
    "            THEN 'Revenue' \n",
    "        WHEN ContainerType = 'Expense' AND (QualifiedCategory = 'Expense.DirectCosts' OR QualifiedCategory like '%Expense.Cost of Goods Sold%' OR QualifiedCategory like '%Cogs%')\n",
    "            THEN 'CostOfSales'\n",
    "        WHEN ContainerType = 'Expense' AND (QualifiedCategory = 'Expense.Overhead' OR QualifiedCategory like '%Expense.Expense%') \n",
    "            THEN 'OperationalCosts'    \n",
    "        WHEN ContainerType = 'Expense' AND (QualifiedCategory like '%Expense.Other Expense%') \n",
    "            THEN 'NonOperationalCosts'    \n",
    "        WHEN ContainerType = 'Assets' AND QualifiedCategory like '%Asset.Fixed%' AND QualifiedName <> 'Asset.Fixed.Intangibles' \n",
    "            THEN 'FixedTangibleAssets'\n",
    "                WHEN ContainerType = 'Assets' AND QualifiedCategory like '%Asset.Fixed%' AND QualifiedName ='Asset.Fixed.Intangibles' \n",
    "            THEN 'FixedIntangibleAssets'\n",
    "        WHEN ContainerType = 'Assets' AND QualifiedCategory NOT like '%Asset.Fixed%' \n",
    "            THEN 'CurrentAssets'\n",
    "        WHEN ContainerType = 'Liabilities' AND (QualifiedCategory like '%NonCurrent%' OR QualifiedCategory like '%Long Term%')\n",
    "            THEN 'LongTermLiabilities'\n",
    "        WHEN ContainerType = 'Liabilities' AND NOT (QualifiedCategory like '%NonCurrent%' OR QualifiedCategory like '%Long Term%') \n",
    "            THEN 'CurrentLiabilities'\n",
    "        WHEN ContainerType = 'Equity' \n",
    "            THEN 'CapitalAndReserve'\n",
    "        ELSE 'Unallocated' \n",
    "        END as CommonCategory,\n",
    "        BalanceCurrent\n",
    "   FROM Accounts \n",
    "   WHERE PartyId  in (\n",
    "       SELECT *\n",
    "       FROM STRING_SPLIT(@listOfIds, ',')\n",
    "       )\n",
    "\n",
    "\n",
    "   \"\"\", (party1))\n",
    "\n",
    "        \n",
    "   cols = [desc[0] for desc in c.description]\n",
    "   Acc_cat_df = pd.DataFrame(np.asarray(c.fetchall()), columns = cols)\n",
    "\n",
    "   return (Acc_cat_df)\n",
    "\n",
    "p = '1668, 1751'\n",
    "\n",
    "#Acc_detail_df = categorisation('1668,1751')\n",
    "Acc_detail_df = categorisation(p)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#print(Acc_detail_df[Acc_detail_df['CommonCategory'] == 'Unallocated'], end='')\n",
    "#print(Acc_detail_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "includeKeyWords = ['Market', '& Sales', \"Advertsing\"]\n",
    "Market_str = '|'.join(includeKeyWords)\n",
    "Market_mask = Acc_detail_df.stack().str.contains(Market_str).any(level=0)\n",
    "Acc_detail_df.loc[Market_mask,'CommonCategory'] = 'AdvertisingAndMarketing'\n",
    "\n",
    "OthOps_mask= Acc_detail_df['CommonCategory'] == 'OperationalCosts' \n",
    "Acc_detail_df.loc[OthOps_mask,'CommonCategory'] = 'OtherOperationalCosts'\n",
    "\n",
    "\n",
    "#print(Acc_detail_df.groupby('CommonCategory').agg({'CommonCategory':'count','BalanceCurrent':'sum'}))\n",
    "\n",
    "includeKeyWords = ['Depr', 'depr']\n",
    "Deprec_str = '|'.join(includeKeyWords)\n",
    "Expense_str = 'Expense'\n",
    "Deprec_mask = Acc_detail_df.stack().str.contains(Deprec_str).any(level=0) \n",
    "Expense_mask = Acc_detail_df.stack().str.contains(Expense_str).any(level=0) \n",
    "Deprec_Expense_mask = Deprec_mask & Expense_mask\n",
    "#Deprec_df = Acc_detail_df[Deprec_mask]\n",
    "Acc_detail_df.loc[Deprec_Expense_mask,'CommonCategory'] = 'DepreciationExpense'\n",
    "#print(Acc_detail_df)\n",
    "#print(np.shape(Deprec_mask))\n",
    "#print(Acc_detail_df.groupby('Common_Category').agg({'Common_Category':'count','BalanceCurrent':'sum'}))\n",
    "\n",
    "#print(Deprec_df)\n",
    "\n",
    "includeKeyWords = ['Finance charge', 'Interest', \"Bank Fees\"]\n",
    "Fin_charge_str = '|'.join(includeKeyWords)\n",
    "Fin_charge_mask = Acc_detail_df.stack().str.contains(Fin_charge_str).any(level=0)\n",
    "#Fin_charge_df = Acc_detail_df[Fin_charge_mask]\n",
    "Acc_detail_df.loc[Fin_charge_mask,'CommonCategory'] = 'InterestExpense'\n",
    "\n",
    "#print(Fin_charge_df)\n",
    "\n",
    "includeKeyWords = ['Taxation', 'Tax', \"VAT\", \"PAYE\"]\n",
    "Tax_str = '|'.join(includeKeyWords)\n",
    "Expense_str = 'Expense'\n",
    "Tax_mask = Acc_detail_df.stack().str.contains(Tax_str).any(level=0)\n",
    "Expense_mask = Acc_detail_df.stack().str.contains(Expense_str).any(level=0) \n",
    "Tax_Expense_mask = Tax_mask & Expense_mask\n",
    "Acc_detail_df.loc[Tax_Expense_mask,'CommonCategory'] = 'TaxExpense'\n",
    "#Tax_df = Acc_detail_df[Tax_mask]\n",
    "#print(Tax_df)\n",
    "\n",
    "includeKeyWords = ['accumulated', 'Accumulated']\n",
    "Acc_deprec_str = '|'.join(includeKeyWords)\n",
    "Assets_str = 'Assets'\n",
    "Acc_deprec_mask = Acc_detail_df.stack().str.contains(Deprec_str).any(level=0)\n",
    "Assets_mask = Acc_detail_df.stack().str.contains(Assets_str).any(level=0) \n",
    "Acc_Depr_Assets_mask = Acc_deprec_mask & Assets_mask\n",
    "Acc_detail_df.loc[Acc_Depr_Assets_mask,'CommonCategory'] = 'AccumulatedDepreciation'\n",
    "\n",
    "\n",
    "#print(Acc_detail_df.groupby(['PartyId','CommonCategory']).agg({'CommonCategory':'count','BalanceCurrent':'sum'}))\n",
    "#PnL_1668_1751_detail_df.groupby('Common_Category').agg({'Common_Category':'count','BalanceCurrent':'sum'})\n",
    "\n",
    "\n",
    "#pd.DataFrame(Acc_detail_df).to_csv(\"\\\\Users\\kenhr\\OneDrive\\Documents\\Ken\\OBR\\Analytical kernel\\AccountingTest\\Categorisation.csv\", header=None, index=None)\n",
    "#pd.DataFrame(Acc_detail_df).to_csv(\"\\\\Users\\kenhr\\Categorisation.csv\", header=CategoryHeader, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "#print(Acc_detail_df[Acc_detail_df['PartyId'] == 1751].groupby(['PartyId','CommonCategory']).agg({'CommonCategory':'count','BalanceCurrent':'sum'}))\n",
    "#print(Acc_detail_df.groupby(['PartyId','CommonCategory']).agg({'CommonCategory':'count','BalanceCurrent':'sum'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryHeader = [\n",
    "\"PartyId\",    \n",
    "\"Id\",\n",
    "\"CommonCategory\"]\n",
    "\n",
    "mapping_df = Acc_detail_df[['PartyId', 'Id', \"CommonCategory\"]]\n",
    "\n",
    "mapping_array = np.array(mapping_df)\n",
    "\n",
    "#print(mapping_array)\n",
    "#pd.DataFrame(mapping_df).to_csv(\"\\\\Users\\kenhr\\OneDrive\\Documents\\Ken\\OBR\\Analytical kernel\\AccountingTest\\Categorisation.csv\", header=CategoryHeader, index=None)\n",
    "pd.DataFrame(mapping_df).to_csv(\"\\\\Users\\kenhr\\Categorisation.csv\", header=CategoryHeader, index=None)\n",
    "\n",
    "#pd.DataFrame(Acc_detail_df).to_csv(\"\\\\Users\\kenhr\\OneDrive\\Documents\\Ken\\OBR\\Analytical kernel\\AccountingTest\\Categorisation.csv\", header=None, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategorisationBatchRowFmtDict = {\n",
    "\"Id\" : \"int\",\n",
    "\"PartyId\" : \"int\",\n",
    "\"CommonCategory\" : \"string\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controlling output format\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import math\n",
    "from itertools import chain\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def batch(input_array, batch_size):\n",
    "\n",
    "  nrows, ncols =np.shape(input_array)\n",
    "  number_batches = nrows // batch_size + ( nrows%batch_size > 0 )\n",
    "\n",
    "  if nrows%batch_size == 0 :\n",
    "    last_batch = np.empty( (batch_size, ncols) )\n",
    "  else :  \n",
    "    last_batch = np.empty( (nrows%batch_size, ncols) )\n",
    "  batches = np.reshape(input_array[ : (number_batches - 1) * batch_size , :], ( number_batches -1, batch_size, ncols )) \n",
    "  last_batch = input_array[ (number_batches - 1) * batch_size : nrows , :]\n",
    "  return  (batches, last_batch)\n",
    "\n",
    "def array_to_json(batches, last_batch, header, BatchRowFmtDict, output_key):\n",
    "\n",
    "   num_batches, batch_size, ncols =np.shape(batches)\n",
    "\n",
    "   #b = dict(zip(header, Alloutput_reshape_array[1][:]))\n",
    "        \n",
    "    \n",
    " \n",
    "   items = list(BatchRowFmtDict.keys())\n",
    "    \n",
    "   AllBatch_dump =[]\n",
    "   for batch in range(num_batches)  :\n",
    "      BatchList= []    \n",
    "      for i in range(batch_size):\n",
    "        BatchRowList=[]    \n",
    "        for j, field in enumerate(batches[batch, i,:].ravel().tolist()) :\n",
    "            if BatchRowFmtDict[items[j]] == \"float\" : \n",
    "               BatchRowList.append(field)\n",
    "            elif  BatchRowFmtDict[items[j]] == \"int\" : \n",
    "               BatchRowList.append(int(math.floor(field)))\n",
    "            elif BatchRowFmtDict[items[j]] == \"monthenddt\" : \n",
    "               BatchRowList.append(str((datetime.strptime(field, r\"%Y-%b\") + relativedelta(day=31)).strftime(\"%Y-%m-%d %H:%M:%SZ\"))[:20])\n",
    "            elif BatchRowFmtDict[items[j]] == \"todaydt\" : \n",
    "               BatchRowList.append(str(field.strftime(\"%Y-%m-%d %H:%M:%SZ\")[:20])) \n",
    "            else : BatchRowList.append(field)\n",
    "        BatchRowDict = dict(zip(header, BatchRowList))\n",
    "        BatchList.append(BatchRowDict.copy())\n",
    "      Batch_dump = {}\n",
    "      #Batch_dump = { output_key+str('%')+str(batch) : BatchList }\n",
    "      Batch_dump = { output_key : BatchList }\n",
    "      AllBatch_dump.append(Batch_dump)       \n",
    "   \n",
    "   batch_size, ncols =np.shape(last_batch)\n",
    "      \n",
    "   BatchList=[]   \n",
    "   for i in range(batch_size):\n",
    "      BatchRowList=[]   \n",
    "      for j, field in enumerate(last_batch[i,:].ravel().tolist()) :\n",
    "            if BatchRowFmtDict[items[j]] == \"float\" : \n",
    "               BatchRowList.append(field)\n",
    "            elif  BatchRowFmtDict[items[j]] == \"int\" : \n",
    "               BatchRowList.append(int(math.floor(field)))\n",
    "            elif BatchRowFmtDict[items[j]] == \"monthenddt\" : \n",
    "               BatchRowList.append(str((datetime.strptime(field, r\"%Y-%b\") + relativedelta(day=31)).strftime(\"%Y-%m-%d %H:%M:%SZ\"))[:20])\n",
    "            elif BatchRowFmtDict[items[j]] == \"todaydt\" : \n",
    "               BatchRowList.append(str(field.strftime(\"%Y-%m-%d %H:%M:%SZ\"))[:20]) \n",
    "            else : BatchRowList.append(field)\n",
    "   BatchRowDict = dict(zip(header, BatchRowList))\n",
    "   BatchList.append(BatchRowDict.copy())\n",
    "   Batch_dump = {}\n",
    "   #Batch_dump = { output_key+str('%')+str(batch) : BatchList }\n",
    "   Batch_dump = { output_key : BatchList }\n",
    "   AllBatch_dump.append(Batch_dump)       \n",
    "        \n",
    "   #for x, block in enumerate(BatchRowList) :\n",
    "   #  print(type(BatchRowList[x]))\n",
    "\n",
    "   return AllBatch_dump\n",
    "    \n",
    "#utc = datetime.strptime('2011-01-21 02:37:21', '%Y-%m-%d %H:%M:%S')\n",
    "#datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%SZ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Categorisaton_batches, Categorisaton_last_batch = cat_batch(mapping_array, 500 )\n",
    "#Categorisaton_dump = cat_to_json(Categorisaton_batches, Categorisaton_last_batch, CategoryHeader, CategorisationBatchRowFmtDict, \"Categorisation\")    \n",
    "\n",
    "Categorisaton_batches, Categorisaton_last_batch = batch(mapping_array, 500 )\n",
    "Categorisaton_dump = array_to_json(Categorisaton_batches, Categorisaton_last_batch, CategoryHeader, CategorisationBatchRowFmtDict, \"Categorisation\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Categorisaton_dump)\n",
    "#print(np.shape(Categorisaton_dump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "\n",
    "batches_dump = list(itertools.chain(Categorisaton_dump))\n",
    "filenames = [\"JSONtest\" + str(i) + \".txt\" for i in range(len(batches_dump))]\n",
    "\n",
    "for batch in range(len(batches_dump)) :\n",
    "#for batch in range(4) :\n",
    "    payload = batches_dump[batch]\n",
    "    url = 'https://api.openrep.cloud/development/insightplatform/brokers/v1/analytics/invoke'\n",
    "    headers = {\n",
    "    'Authorization': 'Bearer 46a8150d-9385-49d0-8240-096cc6869382', \n",
    "    'Content-Type' : 'application/json', \n",
    "    'User-Agent': 'PostmanRuntime/7.28.0'\n",
    "    }\n",
    "    \n",
    "    requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "     \n",
    "    with open(str(filenames[batch]), 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            print(json.dumps(payload))\n",
    "    #time.sleep(0.1)        \n",
    "\n",
    "#print(requests.get(url, data= , headers=headers))    \n",
    "#assert batches_dump[0] != batches_dump[1], \"dump are same\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
